{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/03 07:01:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 07:01:35 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"demoapp\") \\\n",
    "      .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD from parallelize    \n",
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD from external Data source\n",
    "rdd2 = spark.sparkContext.textFile(\"../../Overview-06182023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Num,No.,Ticker,Company,Sector,Industry,Country,Market Cap,P/E,Price,Change,Volume',\n",
       " '0,1,A,\"Agilent Technologies, Inc.\",Healthcare,Diagnostics & Research,USA,35.81B,26.67,121.13,-0.08%,3939930',\n",
       " '1,2,AAL,American Airlines Group Inc.,Industrials,Airlines,USA,10.87B,6.24,16.48,-1.02%,22625167',\n",
       " '2,3,AAPL,Apple Inc.,Technology,Consumer Electronics,USA,2925.70B,31.42,184.92,-0.59%,95747006',\n",
       " '3,4,ABBV,AbbVie Inc.,Healthcare,Drug Manufacturers - General,USA,239.75B,32.71,138.64,2.02%,14593437',\n",
       " '4,5,ABC,AmerisourceBergen Corporation,Healthcare,Medical Distribution,USA,36.83B,23.51,183.01,0.62%,2000327',\n",
       " '5,6,ABEV,Ambev S.A.,Consumer Defensive,Beverages - Brewers,Brazil,49.75B,16.01,3.09,-1.28%,20356797',\n",
       " '6,7,ABNB,\"Airbnb, Inc.\",Consumer Cyclical,Travel Services,USA,81.75B,42.88,128.68,0.65%,6883826',\n",
       " '7,8,ABT,Abbott Laboratories,Healthcare,Medical Devices,USA,182.62B,32.19,106.2,1.12%,10012623',\n",
       " '8,9,ACGL,Arch Capital Group Ltd.,Financial,Insurance - Diversified,Bermuda,26.13B,13.71,71.16,1.44%,3296161']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Num,No.,Ticker,Company,Sector,Industry,Country,Market Cap,P/E,Price,Change,Volume'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|dob       |gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|James    |          |Smith   |1991-04-01|M     |3000  |\n",
      "|Michael  |Rose      |        |2000-05-19|M     |4000  |\n",
      "|Robert   |          |Williams|1978-09-05|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Num: integer (nullable = true)\n",
      " |-- No.: integer (nullable = true)\n",
      " |-- Ticker: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Market Cap: string (nullable = true)\n",
      " |-- P/E: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Change: string (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df = spark.read.csv(\"../../Overview-06182023.csv\",header=True, inferSchema=True)\n",
    "csv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+--------------------+------------------+--------------------+-----------+----------+-----+------+------+--------+\n",
      "|Num|No.|Ticker|             Company|            Sector|            Industry|    Country|Market Cap|  P/E| Price|Change|  Volume|\n",
      "+---+---+------+--------------------+------------------+--------------------+-----------+----------+-----+------+------+--------+\n",
      "|  0|  1|     A|Agilent Technolog...|        Healthcare|Diagnostics & Res...|        USA|    35.81B|26.67|121.13|-0.08%| 3939930|\n",
      "|  1|  2|   AAL|American Airlines...|       Industrials|            Airlines|        USA|    10.87B| 6.24| 16.48|-1.02%|22625167|\n",
      "|  2|  3|  AAPL|          Apple Inc.|        Technology|Consumer Electronics|        USA|  2925.70B|31.42|184.92|-0.59%|95747006|\n",
      "|  3|  4|  ABBV|         AbbVie Inc.|        Healthcare|Drug Manufacturer...|        USA|   239.75B|32.71|138.64| 2.02%|14593437|\n",
      "|  4|  5|   ABC|AmerisourceBergen...|        Healthcare|Medical Distribution|        USA|    36.83B|23.51|183.01| 0.62%| 2000327|\n",
      "|  5|  6|  ABEV|          Ambev S.A.|Consumer Defensive| Beverages - Brewers|     Brazil|    49.75B|16.01|  3.09|-1.28%|20356797|\n",
      "|  6|  7|  ABNB|        Airbnb, Inc.| Consumer Cyclical|     Travel Services|        USA|    81.75B|42.88|128.68| 0.65%| 6883826|\n",
      "|  7|  8|   ABT| Abbott Laboratories|        Healthcare|     Medical Devices|        USA|   182.62B|32.19| 106.2| 1.12%|10012623|\n",
      "|  8|  9|  ACGL|Arch Capital Grou...|         Financial|Insurance - Diver...|    Bermuda|    26.13B|13.71| 71.16| 1.44%| 3296161|\n",
      "|  9| 10| ACGLN|Arch Capital Grou...|         Financial|Insurance - Diver...|    Bermuda|    26.50B| 4.18| 19.63|-0.10%|   28769|\n",
      "| 10| 11|   ACI|Albertsons Compan...|Consumer Defensive|      Grocery Stores|        USA|    12.19B| 9.49| 21.37| 0.61%|13976210|\n",
      "| 11| 12|   ACM|               AECOM|       Industrials|Engineering & Con...|        USA|    12.00B|28.58| 86.67| 0.42%| 2080228|\n",
      "| 12| 13|   ACN|       Accenture plc|        Technology|Information Techn...|    Ireland|   204.47B|29.41|319.54|-1.31%| 5259178|\n",
      "| 13| 14|  ADBE|          Adobe Inc.|        Technology|Software - Infras...|        USA|   225.18B|47.28|495.18| 0.87%|13324076|\n",
      "| 14| 15|   ADI|Analog Devices, Inc.|        Technology|      Semiconductors|        USA|    95.10B|26.69|188.36|-0.69%| 6886920|\n",
      "| 15| 16|   ADM|Archer-Daniels-Mi...|Consumer Defensive|       Farm Products|        USA|    40.61B| 9.47| 75.48| 1.23%| 5522403|\n",
      "| 16| 17|   ADP|Automatic Data Pr...|       Industrials|Staffing & Employ...|        USA|    91.29B|28.27|221.32| 0.16%| 3335514|\n",
      "| 17| 18|  ADSK|      Autodesk, Inc.|        Technology|Software - Applic...|        USA|    47.32B|55.38| 213.5|-3.58%| 3287110|\n",
      "| 18| 19|   AEE|  Ameren Corporation|         Utilities|Utilities - Regul...|        USA|    22.05B|20.16| 84.08| 0.13%| 2812984|\n",
      "| 19| 20|   AEG|          Aegon N.V.|         Financial|Insurance - Diver...|Netherlands|    10.29B|    -|  4.79|-2.44%| 1361677|\n",
      "+---+---+------+--------------------+------------------+--------------------+-----------+----------+-----+------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Ticker|\n",
      "+------+\n",
      "|     A|\n",
      "|  ABBV|\n",
      "|   ABC|\n",
      "|   ABT|\n",
      "|   ALC|\n",
      "|  ALGN|\n",
      "|  ALNY|\n",
      "|  AMGN|\n",
      "|  APLS|\n",
      "|  ARGX|\n",
      "|   AZN|\n",
      "|   BAX|\n",
      "|   BDX|\n",
      "|  BGNE|\n",
      "|  BIIB|\n",
      "|   BIO|\n",
      "|  BMRN|\n",
      "|   BMY|\n",
      "|  BNTX|\n",
      "|  BRKR|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.select(\"Ticker\").filter(\"Sector = 'Healthcare'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df.createOrReplaceTempView(\"csv_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = spark.sql(\"select Sector, count(*) as ticker_cnt from csv_table where Volume > 2000000 group by Sector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['Sector], ['Sector, 'count(1) AS ticker_cnt#150]\n",
      "+- 'Filter ('Volume > 2000000)\n",
      "   +- 'UnresolvedRelation [csv_table], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Sector: string, ticker_cnt: bigint\n",
      "Aggregate [Sector#58], [Sector#58, count(1) AS ticker_cnt#150L]\n",
      "+- Filter (Volume#65 > 2000000)\n",
      "   +- SubqueryAlias csv_table\n",
      "      +- View (`csv_table`, [Num#54,No.#55,Ticker#56,Company#57,Sector#58,Industry#59,Country#60,Market Cap#61,P/E#62,Price#63,Change#64,Volume#65])\n",
      "         +- Relation [Num#54,No.#55,Ticker#56,Company#57,Sector#58,Industry#59,Country#60,Market Cap#61,P/E#62,Price#63,Change#64,Volume#65] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [Sector#58], [Sector#58, count(1) AS ticker_cnt#150L]\n",
      "+- Project [Sector#58]\n",
      "   +- Filter (isnotnull(Volume#65) AND (Volume#65 > 2000000))\n",
      "      +- Relation [Num#54,No.#55,Ticker#56,Company#57,Sector#58,Industry#59,Country#60,Market Cap#61,P/E#62,Price#63,Change#64,Volume#65] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[Sector#58], functions=[count(1)], output=[Sector#58, ticker_cnt#150L])\n",
      "   +- Exchange hashpartitioning(Sector#58, 200), ENSURE_REQUIREMENTS, [plan_id=76]\n",
      "      +- HashAggregate(keys=[Sector#58], functions=[partial_count(1)], output=[Sector#58, count#155L])\n",
      "         +- Project [Sector#58]\n",
      "            +- Filter (isnotnull(Volume#65) AND (Volume#65 > 2000000))\n",
      "               +- FileScan csv [Sector#58,Volume#65] Batched: false, DataFilters: [isnotnull(Volume#65), (Volume#65 > 2000000)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/ananth/code/data-engineering/Overview-06182023.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Volume), GreaterThan(Volume,2000000)], ReadSchema: struct<Sector:string,Volume:int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sum_df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
